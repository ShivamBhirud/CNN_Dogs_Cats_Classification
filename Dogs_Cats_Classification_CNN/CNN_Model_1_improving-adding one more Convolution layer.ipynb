{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Sat Apr 11 21:17:36 2020\n",
    "\n",
    "@author: shivam\n",
    "\"\"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten, Dropout\n",
    "import keras\n",
    "from keras import optimizers\n",
    "\n",
    "# Initialize CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step1: Convolution\n",
    "# 32, (3, 3) means we are using 32 filters with dimention 3x3. \n",
    "# And input_shape means our input image will have 64x64 dimension and it has RGB color format i.e. 3. \n",
    "# If the input image would have been black and white then replace 3 by 1 in input_shape.\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (64, 64, 3), activation= 'relu'))\n",
    "# Step2: Pooling\n",
    "# Pool_size is the size of pooling filter i.e 2x2 in this case.\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Add one more Convolution layer\n",
    "classifier.add(Convolution2D(32, (3, 3), activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# Add one more Convolution layer\n",
    "classifier.add(Convolution2D(32, (3, 3), activation= 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step3: Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step4: Full Connection\n",
    "classifier.add(Dense(activation = 'relu', units = 128))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(activation = 'softmax', units = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compiling the NN\n",
    "classifier.compile(optimizer = keras.optimizers.Adam(lr=.0001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8048 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "126/126 [==============================] - 362s 3s/step - loss: 0.6886 - accuracy: 0.5337 - val_loss: 0.6630 - val_accuracy: 0.6040\n",
      "Epoch 2/25\n",
      "126/126 [==============================] - 359s 3s/step - loss: 0.6635 - accuracy: 0.5929 - val_loss: 0.6474 - val_accuracy: 0.6390\n",
      "Epoch 3/25\n",
      "126/126 [==============================] - 320s 3s/step - loss: 0.6321 - accuracy: 0.6428 - val_loss: 0.6192 - val_accuracy: 0.6760\n",
      "Epoch 4/25\n",
      "126/126 [==============================] - 364s 3s/step - loss: 0.5984 - accuracy: 0.6803 - val_loss: 0.4894 - val_accuracy: 0.7140\n",
      "Epoch 5/25\n",
      "126/126 [==============================] - 341s 3s/step - loss: 0.5785 - accuracy: 0.7022 - val_loss: 0.5114 - val_accuracy: 0.7325\n",
      "Epoch 6/25\n",
      "126/126 [==============================] - 264s 2s/step - loss: 0.5667 - accuracy: 0.7099 - val_loss: 0.5038 - val_accuracy: 0.7305\n",
      "Epoch 7/25\n",
      "126/126 [==============================] - 267s 2s/step - loss: 0.5518 - accuracy: 0.7197 - val_loss: 0.6180 - val_accuracy: 0.7420\n",
      "Epoch 8/25\n",
      "126/126 [==============================] - 262s 2s/step - loss: 0.5424 - accuracy: 0.7310 - val_loss: 0.3828 - val_accuracy: 0.7480\n",
      "Epoch 9/25\n",
      "126/126 [==============================] - 269s 2s/step - loss: 0.5370 - accuracy: 0.7297 - val_loss: 0.4251 - val_accuracy: 0.7485\n",
      "Epoch 10/25\n",
      "126/126 [==============================] - 289s 2s/step - loss: 0.5254 - accuracy: 0.7418 - val_loss: 0.5693 - val_accuracy: 0.7600\n",
      "Epoch 11/25\n",
      "126/126 [==============================] - 315s 3s/step - loss: 0.5276 - accuracy: 0.7367 - val_loss: 0.4692 - val_accuracy: 0.7630\n",
      "Epoch 12/25\n",
      "126/126 [==============================] - 273s 2s/step - loss: 0.5139 - accuracy: 0.7480 - val_loss: 0.3320 - val_accuracy: 0.7665\n",
      "Epoch 13/25\n",
      "126/126 [==============================] - 259s 2s/step - loss: 0.5001 - accuracy: 0.7581 - val_loss: 0.5318 - val_accuracy: 0.7735\n",
      "Epoch 14/25\n",
      "126/126 [==============================] - 264s 2s/step - loss: 0.4983 - accuracy: 0.7583 - val_loss: 0.4844 - val_accuracy: 0.7670\n",
      "Epoch 15/25\n",
      "126/126 [==============================] - 322s 3s/step - loss: 0.4853 - accuracy: 0.7680 - val_loss: 0.2899 - val_accuracy: 0.7800\n",
      "Epoch 16/25\n",
      "126/126 [==============================] - 262s 2s/step - loss: 0.4844 - accuracy: 0.7709 - val_loss: 0.3748 - val_accuracy: 0.7845\n",
      "Epoch 17/25\n",
      "126/126 [==============================] - 279s 2s/step - loss: 0.4773 - accuracy: 0.7721 - val_loss: 0.4598 - val_accuracy: 0.7640\n",
      "Epoch 18/25\n",
      "126/126 [==============================] - 335s 3s/step - loss: 0.4655 - accuracy: 0.7811 - val_loss: 0.3742 - val_accuracy: 0.7725\n",
      "Epoch 19/25\n",
      "126/126 [==============================] - 258s 2s/step - loss: 0.4639 - accuracy: 0.7868 - val_loss: 0.4569 - val_accuracy: 0.7855\n",
      "Epoch 20/25\n",
      "126/126 [==============================] - 262s 2s/step - loss: 0.4536 - accuracy: 0.7911 - val_loss: 0.2715 - val_accuracy: 0.7805\n",
      "Epoch 21/25\n",
      "126/126 [==============================] - 252s 2s/step - loss: 0.4491 - accuracy: 0.7968 - val_loss: 0.4202 - val_accuracy: 0.7945\n",
      "Epoch 22/25\n",
      "126/126 [==============================] - 250s 2s/step - loss: 0.4429 - accuracy: 0.7967 - val_loss: 0.5063 - val_accuracy: 0.8000\n",
      "Epoch 23/25\n",
      "126/126 [==============================] - 258s 2s/step - loss: 0.4380 - accuracy: 0.7995 - val_loss: 0.3522 - val_accuracy: 0.7880\n",
      "Epoch 24/25\n",
      "126/126 [==============================] - 261s 2s/step - loss: 0.4345 - accuracy: 0.7992 - val_loss: 0.3818 - val_accuracy: 0.8065\n",
      "Epoch 25/25\n",
      "126/126 [==============================] - 274s 2s/step - loss: 0.4267 - accuracy: 0.8078 - val_loss: 0.3620 - val_accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fee602f7790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Pre-process our images and Fit CNN to our data. (Keras documentation have this code already)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# generate multiple images from 1 image by shearing, rotating etc.\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "#                          steps_per_epoch=8000, # no of images in our traning set\n",
    "                         epochs=25,\n",
    "                         validation_data=test_set\n",
    "#                          validation_steps=2000\n",
    "                        ) # no of images in our test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog1.jpg', 'cat2.jpg', 'dog2.jpg', 'cat3.jpg', 'dog.jpg', 'cat_or_dog_1.jpg', 'cat.jpg', 'cat_or_dog_2.jpg']\n",
      "dog1.jpg: dog\n",
      "cat2.jpg: cat\n",
      "dog2.jpg: dog\n",
      "cat3.jpg: dog\n",
      "dog.jpg: dog\n",
      "cat_or_dog_1.jpg: dog\n",
      "cat.jpg: dog\n",
      "cat_or_dog_2.jpg: cat\n",
      "Total Dogs : 6\n",
      "Total Cats : 2\n"
     ]
    }
   ],
   "source": [
    "# Make single predicions on random images (neighter in train nor in test data)\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "predict_dir_path='dataset/single_prediction/'\n",
    "onlyfiles = [f for f in listdir(predict_dir_path) if isfile(join(predict_dir_path, f))]\n",
    "print(onlyfiles)\n",
    "\n",
    "\n",
    "dog_counter = 0 \n",
    "cat_counter  = 0\n",
    "for file in onlyfiles:\n",
    "    img = image.load_img(predict_dir_path+file, target_size=(64, 64))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    classes = classifier.predict_classes(images, batch_size=10)\n",
    "    classes = classes[0][0]\n",
    "    \n",
    "    if classes == 0:\n",
    "        print(file + \": \" + 'cat')\n",
    "        cat_counter += 1\n",
    "    else:\n",
    "        print(file + \": \" + 'dog')\n",
    "        dog_counter += 1\n",
    "print(\"Total Dogs :\",dog_counter)\n",
    "print(\"Total Cats :\",cat_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
